{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment 3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB9MWZVkKX4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTKus97LKX4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data\n",
        "data = pd.read_table('C:\\\\Users\\\\Administrator\\\\Desktop\\\\sentiment.analysis\\\\train.txt',header=None)\n",
        "data.columns = ['words','label']\n",
        "\n",
        "test = pd.read_table('C:\\\\Users\\\\Administrator\\\\Desktop\\\\sentiment.analysis\\\\test.txt',header=None)\n",
        "test.columns = ['id','words']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obnmfMPfKX4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean data and remove stopwords \n",
        "def textParse(words):\n",
        "    text = re.sub(\"[^a-zA-Z]\",\" \",words)\n",
        "    wordsList = text.lower().split()\n",
        "    return wordsList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYB6q_AWKX4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = data['label']\n",
        "train_data = []\n",
        "for i in range(len(data['words'])):\n",
        "    train_data.append(' '.join(textParse(data['words'][i])))\n",
        "    \n",
        "test_data = []\n",
        "for i in range(len(test['words'])):\n",
        "    test_data.append(' '.join(textParse(test['words'][i])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_XXb8l7KX4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using tfidf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(min_df=2,max_features = 10000,ngram_range=(1,2),stop_words = 'english')\n",
        "data_all = train_data + test_data\n",
        "data_set = tfidf.fit_transform(data_all)\n",
        "\n",
        "len_train = len(train_data)#8530\n",
        "train_x = data_set[:len_train]\n",
        "test_x = data_set[len_train:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq3sK-H8KX4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(train_x,label,test_size=0.3,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnMxRu-hKX45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train model using SVC','LR','MultinomialNB', 'BernoulliNB','RandomForest\n",
        "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "\n",
        "def multiTest():\n",
        "    ensemble=['SVC','LR','MultinomialNB', 'BernoulliNB','RandomForestClassifier']\n",
        "    for a in ensemble:\n",
        "        classifierResult = []\n",
        "        print(a + ':')\n",
        "        if a == 'SVC':\n",
        "            clf = LinearSVC()\n",
        "            param = {'C': [1e15,1e13,1e11,1e9,1e7,1e5,1e3,1e1,1e-1,1e-3,1e-5]}\n",
        "            clf = GridSearchCV(clf, param, cv=10)\n",
        "        if a == 'LR':\n",
        "            clf = LogisticRegression()\n",
        "        if a == 'MultinomialNB':\n",
        "            clf == MultinomialNB()\n",
        "        if a == 'BernoulliNB':\n",
        "            clf = BernoulliNB()\n",
        "        if a == 'RandomForestClassifier':\n",
        "            clf = RandomForestClassifier(n_estimators=160,max_depth=40,min_samples_split=3,max_features=18)\n",
        "        \n",
        "        clf.fit(x_train,y_train)\n",
        "        y_pre = clf.predict(x_test)\n",
        "                    \n",
        "        print('accuracy_score：',accuracy_score(y_test,y_pre))\n",
        "        print('precision_score：',precision_score(y_test,y_pre))\n",
        "        print('recall_score：',recall_score(y_test,y_pre))\n",
        "        print('F1：',f1_score(y_test,y_pre))\n",
        "        \n",
        "        test_predicted = np.array(clf.predict(test_x))\n",
        "        output = pd.DataFrame(data=test_predicted, columns=['Predicted'])\n",
        "        output['id'] = test['id']\n",
        "        output = output[['id', 'Predicted']]\n",
        "        output.to_csv('C:\\\\Users\\\\Administrator\\\\Desktop\\\\sentiment.analysis\\\\predict_data\\\\tfidf\\\\%i_output.csv'%(ensemble.index(a)), index=False)        \n",
        "\n",
        "multiTest()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMQo0xSgKX5D",
        "colab_type": "code",
        "outputId": "b3f8d515-77de-4fb0-8793-a9ba9c35623c",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "def review_to_wordlist(review, remove_stopwords=False ):\n",
        "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
        "\n",
        "    words = review_text.lower().split()\n",
        "\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "\n",
        "    return(words)\n",
        "\n",
        "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
        "  \n",
        "    raw_sentences = tokenizer.tokenize(review.strip())\n",
        "\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 1:\n",
        "          \n",
        "            sentences.append(review_to_wordlist( raw_sentence, remove_stopwords ))\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
            "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8klAEYDWKX5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "for i, review in enumerate(data[\"words\"]):\n",
        "    sentences += review_to_sentences(review, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzf1gGqvKX5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model parameter \n",
        "\n",
        "import time\n",
        "from gensim.models import Word2Vec\n",
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxszMTwmKX5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDzX1HslKX5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeFeatureVec(words, model, num_features):\n",
        "  \n",
        "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
        "    nwords = 0.\n",
        "\n",
        "   \n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            nwords = nwords + 1.\n",
        "            featureVec = np.add(featureVec, model[word])\n",
        "\n",
        "\n",
        "    featureVec = np.divide(featureVec, nwords)\n",
        "    return featureVec\n",
        "\n",
        "\n",
        "def getAvgFeatureVecs(reviews, model, num_features):\n",
        "   \n",
        "    counter = 0\n",
        "\n",
        "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
        "\n",
        "    for review in reviews:\n",
        "        if counter % 1000 == 0:\n",
        "            print(\"Review %d of %d\" % (counter, len(reviews)))\n",
        "\n",
        "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return reviewFeatureVecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJJIMh0VKX5t",
        "colab_type": "code",
        "outputId": "99a516ed-d960-4c5b-d2b0-7d98ff80e01b",
        "colab": {}
      },
      "source": [
        "trainDataVecs = getAvgFeatureVecs(train_data, model, num_features)\n",
        "testDataVecs = getAvgFeatureVecs(test_data, model, num_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review 0 of 8530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Review 1000 of 8530\n",
            "Review 2000 of 8530\n",
            "Review 3000 of 8530\n",
            "Review 4000 of 8530\n",
            "Review 5000 of 8530\n",
            "Review 6000 of 8530\n",
            "Review 7000 of 8530\n",
            "Review 8000 of 8530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Review 0 of 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATC0TqRqKX53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDataVecs[np.isnan(trainDataVecs)]=np.mean(trainDataVecs[~np.isnan(trainDataVecs)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHtpRJa0KX6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score,precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(trainDataVecs,label,test_size=0.3,random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns_YRu8PKX6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def multiTest1():\n",
        "    ensemble=['SVC','LR','MultinomialNB', 'BernoulliNB','RandomForestClassifier']\n",
        "    for a in ensemble:\n",
        "        classifierResult = []\n",
        "        print(a + ':')\n",
        "        if a == 'SVC':\n",
        "            clf = LinearSVC()\n",
        "        if a == 'LR':\n",
        "            clf = LogisticRegression()\n",
        "        if a == 'MultinomialNB':\n",
        "            clf == MultinomialNB()\n",
        "        if a == 'BernoulliNB':\n",
        "            clf = BernoulliNB()\n",
        "        if a == 'RandomForestClassifier':\n",
        "            clf = RandomForestClassifier(n_estimators=160,max_depth=40,min_samples_split=3,max_features=18)\n",
        "        \n",
        "        clf.fit(x_train,y_train)\n",
        "        y_pre = clf.predict(x_test)\n",
        "                    \n",
        "        print('accuracy_score：',accuracy_score(y_test,y_pre))\n",
        "        print('precision_score：',precision_score(y_test,y_pre))\n",
        "        print('recall_score：',recall_score(y_test,y_pre))\n",
        "        print('F1：',f1_score(y_test,y_pre))\n",
        "        \n",
        "        test_predicted = np.array(clf.predict(testDataVecs))\n",
        "        output = pd.DataFrame(data=test_predicted, columns=['Predicted'])\n",
        "        output['id'] = test['id']\n",
        "        output = output[['id', 'Predicted']]\n",
        "        output.to_csv('C:\\\\Users\\\\Administrator\\\\Desktop\\\\sentiment.analysis\\\\predict_data\\\\word2vec\\\\%i_output.csv'%(ensemble.index(a)), index=False)        \n",
        "\n",
        "\n",
        "multiTest1()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBiJL3NPKX6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}